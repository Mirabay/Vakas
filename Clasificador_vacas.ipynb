{"cells":[{"cell_type":"markdown","metadata":{"id":"277uy1txT7w6"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"mUVO_fOeT9Kp"},"outputs":[],"source":["import torch\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","import torch.nn as nn\n","import torch.optim as optim\n","from tqdm import tqdm\n"]},{"cell_type":"markdown","metadata":{"id":"RJyDuPIMuY-N"},"source":["# Transformaciones"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"CNemHMmOudFm"},"outputs":[],"source":["# Definir transformaciones para las imágenes\n","transform = transforms.Compose([\n","    transforms.Resize((450, 950)),  # Resize the images\n","    transforms.RandomHorizontalFlip(p=0.5),  # Apply horizontal flip with a 50% chance\n","    # transforms.RandomVerticalFlip(p=0.5),    # Apply vertical flip with a 50% chance (optional)\n","    transforms.RandomRotation(degrees=30),   # Randomly rotate the image by up to 30 degrees\n","    # minimun size of the image\n","    transforms.ToTensor(),                   # Convert image to tensor\n","    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the values\n","])"]},{"cell_type":"markdown","metadata":{"id":"ZG5TVm-CIsZn"},"source":["# Extracción"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"emX9mEgurJ_6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Clases encontradas: ['cama_vacia', 'vaca_acostada', 'vaca_de_pie']\n"]}],"source":["# Cargar los conjuntos de datos desde las carpetas separadas\n","train_dataset = ImageFolder(root='dataset_split\\\\train', transform=transform)\n","validation_dataset = ImageFolder(root='dataset_split\\\\validation', transform=transform)\n","test_dataset = ImageFolder(root='dataset_split\\\\test', transform=transform)\n","\n","# Verifica que las clases están correctamente identificadas\n","print(f\"Clases encontradas: {train_dataset.classes}\")"]},{"cell_type":"markdown","metadata":{"id":"C4TvzYx3I0Yr"},"source":["# Dataloaders"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"BYTsHASpI750"},"outputs":[],"source":["# Crear los DataLoader para cada conjunto de datos\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","validation_loader = DataLoader(validation_dataset, batch_size=16, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"bQzXTTQvI5Zb"},"source":["# Modelo"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"9YxOT3MII67A"},"outputs":[],"source":["# Modelo simple (CNN) para clasificación de las tres clases\n","class SimpleCNN(nn.Module):\n","    def __init__(self):\n","        super(SimpleCNN, self).__init__()\n","        self.conv_layer = nn.Sequential(\n","            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2)\n","        )\n","        self.fc_layer = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(16 * 225 * 475, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, 3)  # 3 clases: vaca_de_pie, vaca_acostada, cama_vacia\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_layer(x)\n","        x = self.fc_layer(x)\n","        return x"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"GmguaL-rupaG"},"outputs":[],"source":["# Inicializar el modelo, criterio (loss) y optimizador\n","model = SimpleCNN()\n","criterion = nn.CrossEntropyLoss()  # Para clasificación multiclase\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"]},{"cell_type":"markdown","metadata":{"id":"tIVf4tq1I-Xe"},"source":["# Entrenamiento"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Usando el dispositivo: cuda\n"]}],"source":["# Entrenar con Gpu\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model.to(device)\n","print(f'Usando el dispositivo: {device}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6jAfxVi2I9FF"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1/25:  12%|█▏        | 20/166 [17:31<2:49:44, 69.76s/batch] "]}],"source":["# Hiperparámetros\n","num_epochs = 25\n","\n","# Entrenamiento del modelo\n","for epoch in range(num_epochs):\n","    model.train()  # Modo de entrenamiento\n","    running_loss = 0.0\n","\n","    # Usar tqdm para la barra de progreso\n","    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n","        images, labels = images.to(device), labels.to(device)  # Move to the same device\n","        optimizer.zero_grad()  # Resetear gradientes\n","        outputs = model(images)  # Forward\n","        loss = criterion(outputs, labels)  # Calcular pérdida\n","        loss.backward()  # Backpropagation\n","        optimizer.step()  # Actualizar pesos\n","\n","        running_loss += loss.item()\n","\n","    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}')\n","\n","    # Evaluación en el conjunto de validación\n","    model.eval()  # Modo de evaluación\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():  # No se calculan gradientes en evaluación\n","        for images, labels in validation_loader:\n","            images, labels = images.to(device), labels.to(device)  # Move to the same device\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)  # Predicción\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    validation_accuracy = 100 * correct / total\n","    print(f'Validation Accuracy: {validation_accuracy}%')\n","    \n","        # Guardar el modelo cada 3 epochs\n","    if (epoch + 1) % 3 == 0:\n","        torch.save(model.state_dict(), f'Modelos/model_epoch_{epoch+1}.pth')\n","        print(f'Model saved at epoch {epoch+1}')\n"]},{"cell_type":"markdown","metadata":{"id":"WosWeqhjJD0a"},"source":["# Evaluación de entrenamiento"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Cargar el modelo con mejor precisión en validación\n","model.load_state_dict(torch.load('Modelos/model_epoch_24.pth'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"346Yv50cJFn4"},"outputs":[],"source":["# Evaluación final en el conjunto de prueba\n","model.eval()  # Modo de evaluación\n","correct = 0\n","total = 0\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)  # Move to the same device\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","test_accuracy = 100 * correct / total\n","print(f'Test Accuracy: {test_accuracy}%')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# make a cofusion matrix\n","from sklearn.metrics import confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","model.eval()  # Modo de evaluación\n","y_true = []\n","y_pred = []\n","\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)  # Move to the same device\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        y_true += labels.cpu().numpy().tolist()\n","        y_pred += predicted.cpu().numpy().tolist()\n","\n","cm = confusion_matrix(y_true, y_pred)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(cm, annot=True, fmt='d', xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\n","plt.xlabel('Predicted')\n","plt.ylabel('Actual')\n","plt.title('Confusion Matrix')\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# show some images and their predictions\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","model.eval()  # Modo de evaluación\n","\n","# Get a batch of test images and labels\n","images, labels = next(iter(test_loader))\n","images, labels = images.to(device), labels.to(device)  # Move to the same device\n","\n","# Make predictions\n","outputs = model(images)\n","_, predicted = torch.max(outputs, 1)\n","\n","# Display the images, labels, and model's predictions\n","plt.figure(figsize=(20, 10))\n","for i in range(25):\n","    plt.subplot(5, 5, i + 1)\n","    image = images[i] / 2 + 0.5  # Unnormalize\n","    image = image.cpu().numpy()\n","    plt.imshow(np.transpose(image, (1, 2, 0))\n","               )\n","    plt.axis('off')\n","    plt.title(f'Actual: {train_dataset.classes[labels[i]]}\\nPredicted: {train_dataset.classes[predicted[i]]}')\n","plt.show()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":0}
